# Prueba TÃ©cnica â€“ Data Engineer

En este repositorio se implementa un **proceso ETL** ejecutable tanto **localmente en Python** como mediante **contenedorizaciÃ³n en Airflow**.  
El objetivo es mostrar una soluciÃ³n de **ETL robusta y estructurada**, con capacidad de validaciÃ³n, trazabilidad y fÃ¡cil adaptaciÃ³n a entornos productivos.

---

## ğŸ¯ Objetivos del proyecto

El propÃ³sito central del proyecto es **tomar tres fuentes de datos distintas** (`pays`, `prints`, `taps`) y realizar un **proceso de transformaciÃ³n** que produzca un dataset final listo para ser utilizado por otros modelos dentro del negocio.  

El dataset debÃ­a cumplir con los siguientes requerimientos:  

1. **Obtener los prints de la Ãºltima semana**.
2. Para cada print se construyen los siguientes campos:  
   - **Indicador de click** â†’ si el usuario hizo o no click en el print.  
   - **Cantidad de vistas** â†’ nÃºmero de veces que el usuario vio cada *value prop* en las **3 semanas previas** a ese print.  
   - **Cantidad de clicks** â†’ nÃºmero de veces que el usuario clickeÃ³ cada *value prop* en las **3 semanas previas**.  
   - **Cantidad de pagos** â†’ nÃºmero de pagos realizados por el usuario para cada *value prop* en las **3 semanas previas**.  
   - **Importe acumulado** â†’ total del gasto del usuario en cada *value prop* durante las **3 semanas previas**.  

---

## ğŸ“Œ Supuestos y reglas de negocio

Dado que en el enunciado del problema no existen definiciones formales sobre ciertos conceptos, fue necesario establecer **supuestos** para poder construir un pipeline consistente.  
En un escenario real, para lograr un resultado mÃ¡s alineado a las expectativas del usuario final, se deberÃ­a realizar un proceso de **investigaciÃ³n e indagaciÃ³n directa con el Ã¡rea de negocio** con el fin de resolver ambigÃ¼edades y aclarar dudas.  

Los supuestos definidos para este proyecto son los siguientes:

- **DefiniciÃ³n de â€œsemanaâ€**:  
  Se considera una semana completa (lunes a domingo). Esto elimina la ambigÃ¼edad de tomar â€œÃºltimos 7 dÃ­asâ€ y asegura que los reportes sean **absolutos y repetibles**.  

- **Ventana temporal de anÃ¡lisis**:  
  No se reciben fechas como parÃ¡metro, por lo que los reportes siempre se calculan tomando la **Ãºltima fecha disponible en los datos** como referencia.  
  - Ãšltima semana disponible.  
  - Tres semanas anteriores para consolidar tendencias histÃ³ricas.  
  Si se quisiera consultar cualquier otro periodo arbitrario, el pipeline deberÃ­a extenderse para permitir un **parÃ¡metro de fecha de corte**, que filtre desde quÃ© punto temporal realizar los cÃ¡lculos.  
  En la actualidad, para conseguir este comportamiento serÃ­a necesario **filtrar previamente las bases de datos antes de cargarlas**, lo cual representa un **sobreproceso** que podrÃ­a eliminarse si se implementa dicho parÃ¡metro en etapas posteriores.  

- **Naturaleza de los datos de `prints`**:  
  Cada registro de `prints` corresponde a una **fecha, usuario y `value_prop`** diferente.  
  Por definiciÃ³n, esto puede dar lugar a **repeticiones en la informaciÃ³n**: por ejemplo, si un mismo usuario tiene interacciones con el mismo `value_prop` el lunes y el miÃ©rcoles, el conteo acumulado de las semanas pasadas serÃ¡ idÃ©ntico en ambos registros.  

- **Resultados finales**:  
  - `final.csv`: formato universal, portable a cualquier sistema.  
  - `final.parquet`: optimizado para anÃ¡lisis en data warehouses y lagos de datos.  

ğŸ‘‰ Este diseÃ±o garantiza que los datos sean claros, consistentes y fÃ¡cilmente reutilizables por equipos de BI, ML o analÃ­tica, evitando reprocesamientos adicionales.

---

## ğŸ—ï¸ Arquitectura tÃ©cnica

El proyecto combina varias tecnologÃ­as clave:

### 1. OrquestaciÃ³n con **Airflow**
- Airflow permite definir los pipelines como **DAGs** (Directed Acyclic Graphs).  
- Ventajas:  
  - **Escalabilidad**: fÃ¡cil de extender a mÃºltiples tareas distribuidas.  
  - **Observabilidad**: interfaz grÃ¡fica para visualizar dependencias, logs y ejecuciones.  
  - **Flexibilidad**: soporte para ejecuciÃ³n programada (ej. semanal) o bajo demanda.  
- En este proyecto:  
  - Airflow corre en contenedores Docker.  
  - Incluye Scheduler + Webserver.  
  - InicializaciÃ³n automÃ¡tica con Postgres como metastore.  
  - DAG configurado para correr cada 5 minutos (modo pruebas). En producciÃ³n, puede cambiarse fÃ¡cilmente a una frecuencia semanal.

### 2. Almacenamiento con **MinIO (S3-like)**
- MinIO simula un bucket S3 de AWS en local.  
- Ventajas:  
  - Compatible 100% con APIs S3 â†’ migraciÃ³n inmediata a cloud.  
  - Permite validar flujo **end-to-end** de ingestiÃ³n y exportaciÃ³n.  
  - Facilita pruebas locales sin depender de infraestructura externa.  

### 3. **Polars** como motor de transformaciÃ³n
- Polars se eligiÃ³ por su rendimiento superior a Pandas en escenarios de ETL.  
- Beneficios:  
  - **EjecuciÃ³n en paralelo** con motor basado en Apache Arrow.  
  - **API declarativa** que facilita escritura limpia y mantenible.  
  - **Escalabilidad futura** hacia motores distribuidos.  
- JustificaciÃ³n tÃ©cnica:  
  - Permite procesar datasets mÃ¡s grandes en memoria.  
  - Evita cuellos de botella comunes en Pandas.
  - Es **estricto con el tipado**, lo cual es deseable en proyectos de **data engineering**, ya que reduce errores silenciosos y asegura mayor consistencia en la manipulaciÃ³n de datos.  

### 4. ValidaciÃ³n de datos con **Great Expectations**
- Cada dataset es sometido a validaciones tanto de **esquema** como de **valores**.  
- Los reportes en formato **JSON** permiten una **auditorÃ­a visual** de cada ejecuciÃ³n, registrando informaciÃ³n clave como:  
  - Presencia o ausencia de columnas obligatorias.  
  - ApariciÃ³n de columnas inesperadas.  
  - DetecciÃ³n de valores fuera de rango o inconsistentes.  
- Posible extensiÃ³n:  
  - Almacenar los reportes con un **timestamp** para mantener un histÃ³rico de calidad de datos.  
  - Dicho histÃ³rico facilitarÃ­a el anÃ¡lisis de la **evoluciÃ³n de las fuentes** en el tiempo y permitirÃ­a anticipar fallas o rupturas en la integraciÃ³n.  

### 5. Backend de metadatos con **PostgreSQL**
- Airflow utiliza Postgres como **base de metadatos**.  
- Permite persistir DAGs, estados de ejecuciÃ³n y logs de scheduler.  
- Facilita auditorÃ­a completa del pipeline.

### 6. **Infraestructura contenidizada con Docker Compose**
- Todos los servicios corren en contenedores:  
  - Airflow Webserver.  
  - Airflow Scheduler.  
  - Postgres.  
  - MinIO.  
  - Servicios de inicializaciÃ³n (`init-airflow`, `init-minio`).  
- Ventajas:  
  - Portabilidad â†’ el mismo pipeline corre en cualquier mÃ¡quina.  
  - Aislamiento â†’ cada servicio es independiente.  
  - Facilidad de despliegue â†’ un solo comando levanta toda la infraestructura.

---

## ğŸ“‚ Estructura del repositorio

```bash
.
â”œâ”€â”€ .github/workflows/   # CI: tipado, linting, seguridad, tests
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ runner.py        # EjecuciÃ³n del ETL en local
â”‚   â””â”€â”€ dags/            # DAGs de Airflow
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/             # Datos crudos de entrada (local)
â”‚   â””â”€â”€ out/             # Resultados finales (CSV + Parquet) (local)
â”œâ”€â”€ docs/                # Requerimientos (EN y ES)
â”œâ”€â”€ envis/               # Variables de entorno (local + docker)
â”œâ”€â”€ expectations/        # Reportes de Great Expectations
â”œâ”€â”€ infra/               # Docker Compose + servicios Airflow y MinIO
â”œâ”€â”€ metadata/            # DocumentaciÃ³n de esquemas esperados en los datasets
â”œâ”€â”€ notebooks/           # ExploraciÃ³n y prototipado del ETL
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ adapters/        # Utilidades (logs, lectores, helpers)
â”‚   â”œâ”€â”€ application/     # LÃ³gica central del ETL
â”‚   â”œâ”€â”€ config/          # ConfiguraciÃ³n de entornos
â”‚   â””â”€â”€ domain/          # Definiciones de modelos/esquemas
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ unit/            # Unit tests de cada mÃ³dulo
â”‚       â””â”€â”€ data/        # Fixtures y datos de apoyo
â”œâ”€â”€ Makefile             # Comandos automatizados
â”œâ”€â”€ requirements.txt     # Dependencias de producciÃ³n
â””â”€â”€ requirements-dev.txt # Dependencias de desarrollo
```

---

## ğŸ“Š Logs y Auditabilidad

### Logging
- ImplementaciÃ³n de logs con distintos niveles (`INFO`, `DEBUG`, `ERROR`) utilizando la librerÃ­a estÃ¡ndar de Python: **`logging`**.  
- Logs centralizados en adaptadores (`src/adapters/logging`).  
- Cada transformaciÃ³n y validaciÃ³n queda registrada en tiempo real.  
- Ventajas:  
  - Permite **auditorÃ­a paso a paso** del pipeline.  
  - Facilita el **troubleshooting en producciÃ³n** con trazas claras.  
  - Aporta **robustez ante fallas**, ya que cada error queda registrado con contexto tÃ©cnico.  
  - Mejora la **observabilidad** y la **mantenibilidad** del proceso ETL.  

### Auditabilidad
- Great Expectations + logs garantizan trazabilidad total.  
- Cambios en fuentes se detectan automÃ¡ticamente.  
- Posibilidad de mantener un **histÃ³rico de reportes de calidad**, solo cambiando el nombre de salida a formato `YYYY-MM-DD_report.html`.

---

## ğŸ”„ CI/CD y calidad

La polÃ­tica es clara: **si algÃºn paso falla, el pipeline completo falla** y la ejecuciÃ³n queda marcada como **fallida** en GitHub Actions.  
Esto garantiza visibilidad inmediata de errores y evita que se avance con cÃ³digo en mal estado hacia producciÃ³n. 

### 1. Tipado estÃ¡tico â€“ `mypy`
- Garantiza que el cÃ³digo cumple con anotaciones de tipos estrictas.  
- En data engineering esto es clave: evita errores silenciosos al manejar estructuras de datos complejas (ej. `DataFrame` â†’ `Series`).  
- La verificaciÃ³n de tipos aporta **robustez y mantenibilidad**, minimizando bugs en producciÃ³n.

### 2. Linting â€“ `flake8`
- Asegura que el cÃ³digo cumple con convenciones **PEP8**.  
- Detecta imports sin uso, variables mal definidas y problemas de estilo que a la larga generan deuda tÃ©cnica.  
- Contribuye a la **legibilidad** y a la colaboraciÃ³n en equipo.

### 3. Seguridad â€“ `bandit` + `pip-audit`
- `bandit`: analiza patrones de cÃ³digo en busca de vulnerabilidades (ej. uso inseguro de `eval`, problemas de criptografÃ­a, hardcodeo de credenciales).  
- `pip-audit`: revisa dependencias contra bases de datos de vulnerabilidades conocidas (CVE).  
  - Gracias a esta verificaciÃ³n se detectÃ³ que las librerÃ­as usadas por defecto en GitHub Actions incluÃ­an una versiÃ³n vulnerable de **`setuptools`**.  
  - El problema se solucionÃ³ actualizando manualmente la librerÃ­a al inicio del workflow, asegurando que las dependencias del proyecto se instalen siempre en versiones seguras.
- Esta combinaciÃ³n garantiza que el pipeline sea **seguro por diseÃ±o**.

### 4. Testing â€“ `pytest` con cobertura
- La cobertura global del proyecto es de **95.49%**, superando ampliamente el umbral mÃ­nimo definido en el CI.  
- El pipeline aplica una polÃ­tica estricta e **inmutable**:  
  - **Cobertura <80% â†’ ejecuciÃ³n fallida automÃ¡ticamente** (no se permite continuar el flujo).  
- La mayorÃ­a de los mÃ³dulos crÃ­ticos mantienen **100% de cobertura**, lo que respalda la confiabilidad de las transformaciones y reglas de negocio centrales.  
- Se implementaron **53 tests unitarios**, cubriendo tanto escenarios comunes como casos lÃ­mite y validaciones de errores, lo que garantiza un conjunto robusto de pruebas.  
- La estrategia no busca el 100% absoluto, sino asegurar la **estabilidad y calidad real en componentes clave**.  
- Los tests estÃ¡n diseÃ±ados de forma **modular y escalable**, permitiendo que la suite crezca sin fricciÃ³n a medida que se incorporen nuevas funcionalidades al pipeline.  

---

### Estrategia de branching
- El pipeline de CI actualmente estÃ¡ configurado para ejecutarse en **push directo a `master`**, garantizando que el estado de esa rama siempre sea estable.  
- En un entorno productivo, lo mÃ¡s recomendable es habilitar CI en **Pull Requests hacia `master` o `testing`**, de forma que la validaciÃ³n se ejecute antes de la integraciÃ³n.  
- Esto asegura que **ningÃºn cambio defectuoso llegue a producciÃ³n**, y que el cÃ³digo se valide siempre en el mismo entorno que serÃ¡ desplegado.  

### ExtensiÃ³n a CD
- La implementaciÃ³n de CD es inmediata gracias a la arquitectura basada en contenedores.  
- BastarÃ­a con:
  1. Asociar el servidor productivo con **runners de GitHub Actions**.  
  2. En el pipeline, agregar un job que haga **build y push** de la imagen Docker generada a un registry.  
  3. El runner en el servidor ejecuta `docker-compose pull && docker-compose up -d` para levantar la nueva versiÃ³n automÃ¡ticamente.  

Este diseÃ±o asegura un flujo **reproducible y confiable** de cÃ³digo â†’ build â†’ test â†’ despliegue, sin intervenciÃ³n manual.  

---

## ğŸ› ï¸ EjecuciÃ³n local (Python)

Para correr el proyecto en un entorno local se requiere:  
1. Descargar el repositorio.  
2. Tener instalado `make` en el sistema.  
3. Crear un entorno virtual de Python (`venv`) e instalar las dependencias de desarrollo listadas en `requirements_dev.txt`.  

Una vez configurado el entorno y activado, los comandos principales son:  

- `make run-local` â†’ ejecuta el ETL completo en local, procesando los datasets y generando las salidas (`csv` y `parquet`).  
- `make all` â†’ corre de forma automÃ¡tica todas las validaciones de calidad: tipado, linting, seguridad y tests con cobertura.  

ğŸ‘‰ Esta capa de automatizaciÃ³n estandariza los procesos de desarrollo, evita errores manuales y asegura que todos los desarrolladores trabajen con el **mismo flujo de ejecuciÃ³n y validaciÃ³n**.  

ğŸ“Œ Nota: ademÃ¡s de los comandos principales, existen otros Ãºtiles y mÃ¡s especÃ­ficos. Se pueden consultar directamente en el `Makefile` para conocer todas las opciones disponibles.  

---

## ğŸ³ EjecuciÃ³n con Docker y Airflow

Para correr el proyecto en contenedores:

1. Entrar a la carpeta de infraestructura:

```bash
cd infra/
```

2. Levantar los servicios con: 

```bash
docker-compose up -d --build
```

Una vez ejecutado el comando, es necesario **esperar unos segundos** hasta que los contenedores terminen de inicializarse y configurarse.  

### Acceso a servicios principales

- **Airflow Web UI** â†’ [http://localhost:8080](http://localhost:8080)  
  - Usuario: `admin`  
  - Password: `admin`  
  - AquÃ­ puedes consultar los **logs detallados**, la **estadÃ­stica de las ejecuciones** y la **visualizaciÃ³n de los DAGs**.  

- **MinIO** â†’ [http://localhost:9091](http://localhost:9091)  
  - Usuario: `minio`  
  - Password: `minio123`  
  - Permite inspeccionar directamente los archivos almacenados, funcionando como una **visual del repositorio de datos**.  

### Comportamiento automÃ¡tico
- Al iniciar los contenedores, las bases de datos de prueba se copian automÃ¡ticamente en MinIO para mayor comodidad en el desarrollo.  
- Airflow lanza un **primer job de ETL automÃ¡ticamente** apenas se termina de levantar el contenedor.  
- A partir de ahÃ­, el DAG queda configurado para ejecutarse **cada 5 minutos (en mÃºltiplos de 5)** de manera recurrente.  
- Opcionalmente, en lugar de esperar al scheduler, se puede entrar a la interfaz de Airflow y **ejecutar manualmente el DAG** con un clic en â€œTrigger DAGâ€.  

---

## ğŸš€ Escalabilidad y mejoras

El proyecto fue diseÃ±ado con visiÃ³n productiva y contempla mÃºltiples rutas de evoluciÃ³n hacia entornos empresariales:

- **MigraciÃ³n cloud nativa**  
  - Sustituir MinIO por **AWS S3** o **Google Cloud Storage (GCS)** como data lake.  
  - Reemplazar Airflow local por **MWAA (Managed Workflows for Apache Airflow)** en AWS o **Cloud Composer** en GCP.  
  - IntegraciÃ³n con servicios de IAM para **gestiÃ³n granular de accesos** y compliance.  

- **Procesamiento distribuido**  
  - Migrar los procesos de Polars a **PySpark o Dask**, habilitando procesamiento de datasets en el orden de **terabytes**.  
  - OptimizaciÃ³n de **particionamiento y paralelismo** para ETL de alto rendimiento.  
  - Uso de **cluster autoscaling** en cloud para balancear costo y performance.  

- **CD automatizado**  
  - Configurar un **self-hosted runner** de GitHub Actions conectado al servidor de despliegue.  
  - Pipeline extendido para **build + push de imÃ¡genes Docker** a un registry (ECR/GCR).  
  - CD real: servidor con `docker-compose pull && docker-compose up -d` â†’ despliegue sin intervenciÃ³n manual.  

- **Observabilidad y alertas**  
  - Integrar Airflow y Great Expectations con **Prometheus + Grafana** para mÃ©tricas y dashboards centralizados.  
  - ConfiguraciÃ³n de **alertas proactivas en Slack/Email** para:  
    - Fallos en DAGs.  
    - Validaciones de datos que rompan expectativas.  
    - DegradaciÃ³n de performance en jobs crÃ­ticos.  

- **GestiÃ³n de calidad de datos**  
  - Versionado de reportes de Great Expectations en formato **parquet/JSON** dentro de buckets.  
  - ConstrucciÃ³n de un **histÃ³rico de calidad** consultable para detectar tendencias en la evoluciÃ³n de las fuentes.  
  - Potencial integraciÃ³n con **Data Catalog** (Glue Data Catalog, BigQuery Data Catalog).  

- **Seguridad avanzada (Hardening)**  
  - Sustituir `.env` locales por **secrets managers** (AWS Secrets Manager, GCP Secret Manager, HashiCorp Vault).  
  - IntegraciÃ³n con **escaneo continuo de dependencias y contenedores** (Trivy, Grype).  
  - PolÃ­ticas de **least privilege** en usuarios y roles de orquestadores y buckets.  

- **PrÃ³ximos pasos de automatizaciÃ³n**  
  - ImplementaciÃ³n de **data lineage automÃ¡tico** con herramientas como **OpenLineage/Marquez**.  
  - OrquestaciÃ³n hÃ­brida de DAGs â†’ ejecuciÃ³n condicional de workflows segÃºn calidad de inputs.  
  - EvaluaciÃ³n de **feature store** para centralizar transformaciones crÃ­ticas si se avanza hacia ML.  